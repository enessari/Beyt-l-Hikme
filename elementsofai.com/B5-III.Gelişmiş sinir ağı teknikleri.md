




![img](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8"?>
<svg width="923px" height="230px" viewBox="0 0 923 230" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 49 (51002) - http://www.bohemiancoding.com/sketch -->
    <title>Artboard 2 Copy</title>
    <desc>Created with Sketch.</desc>
    <defs></defs>
    <g id="Artboard-2-Copy" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Group-22-Copy-3" transform="translate(2.000000, 25.000000)">
            <g id="Group-6">
                <g id="Group-4">
                    <g id="Group-16-Copy-3" transform="translate(41.340224, 26.000000)">
                        <path d="M397.4152,186.805556 L423.262156,129.048428 L433.656216,113.822368 L469.148811,4.40350877 L575.688705,107.700567 L582.719524,20.9829955 L482.356441,4.40350877 L447.36383,8.83059211 L333.901809,56.8792032 L429.786781,120.930556 M508.781976,186.805556 L437.469753,129.048428 L442.804977,120.883955 L569.257244,109.522661 L571.566172,109.522661 L544.105916,182.42818 M632.393583,182.42818 L575.688705,109.522661" id="Path-66" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M316.989334,59.2807018 L201.148512,72.4718567" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M267.928873,124.963085 L192.403464,73.2671784" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M100.639471,36.1977339 L192.403464,73.2671784" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M245.258829,4.00584795 L192.403464,73.2671784" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M245.258829,4.00584795 L340.659345,63.6549708" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M245.258829,4.00584795 L104.543066,31.8421053" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M97.3880276,37.4093567 L166.553402,181.362573" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M92.6180017,35.0233918 L0.397502153,153.526316" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M267.928873,124.963085 L332.324222,58.9513889" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M349.814317,225.968933 L332.324222,58.9513889" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M267.928873,124.963085 L171.733352,176.658991" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M271.159776,126.5 L267.928873,215.629751" id="Path-8" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M572.23851,109.13432 L677.188395,90.4256213" id="Path-2" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M581.54565,22.2982456 L677.188395,90.4256213" id="Path-2" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M676.151163,81.9473684 L665.816107,0.824561404" id="Path-2" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M807.326873,91.4912281 L665.816107,0.824561404" id="Path-2" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M808.916882,92.2865497 L838.332041,191.701754" id="Path-2" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M808.916882,92.2865497 L716.696382,171.023392" id="Path-2" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M805.736865,93.0818713 L680.126184,90.6959064" id="Path-2" stroke="#D0E0E5" stroke-width="9"></path>
                        <path d="M707.156331,151.935673 L680.126184,90.6959064" id="Path-2" stroke="#D0E0E5" stroke-width="9"></path>
                        <ellipse id="Oval-7" fill="#1274BF" cx="427.712317" cy="119.725146" rx="37.3652024" ry="37.380117"></ellipse>
                        <ellipse id="Oval-7-Copy" fill="#1274BF" cx="715.489262" cy="171.435673" rx="25.4255238" ry="25.4356725"></ellipse>
                        <ellipse id="Oval-7-Copy-4" fill="#1274BF" cx="839.127046" cy="200.450292" rx="42.5327304" ry="42.5497076"></ellipse>
                        <ellipse id="Oval-7-Copy-12" fill="#1274BF" cx="807.326873" cy="91.4912281" rx="20.2726098" ry="20.2807018"></ellipse>
                        <ellipse id="Oval-7-Copy-2" fill="#1274BF" cx="333.504307" cy="58.0877193" rx="31.4026701" ry="31.4152047"></ellipse>
                        <ellipse id="Oval-7-Copy-3" fill="#1274BF" cx="160.988372" cy="177.385965" rx="31.4026701" ry="31.4152047"></ellipse>
                        <ellipse id="Oval-7-Copy-6" fill="#1274BF" cx="580.750646" cy="19.9122807" rx="16.2975883" ry="16.3040936"></ellipse>
                        <ellipse id="Oval-7-Copy-5" fill="#1274BF" cx="571.608096" cy="109.385965" rx="26.2351421" ry="26.245614"></ellipse>
                        <ellipse id="Oval-7-Copy-10" fill="#1274BF" cx="678.933678" cy="91.8888889" rx="20.670112" ry="20.6783626"></ellipse>
                    </g>
                    <ellipse id="Oval-7-Copy-7" fill="#1274BF" cx="508.405254" cy="28.4152047" rx="28.2226529" ry="28.2339181"></ellipse>
                    <ellipse id="Oval-7-Copy-9" fill="#1274BF" cx="708.746339" cy="28.4152047" rx="28.2226529" ry="28.2339181"></ellipse>
                    <ellipse id="Oval-7-Copy-8" fill="#1274BF" cx="233.731266" cy="98.8011696" rx="23.8501292" ry="23.8596491"></ellipse>
                    <ellipse id="Oval-7-Copy-20" fill="#1274BF" cx="284.611542" cy="29.6081871" rx="15.1050818" ry="15.1111111"></ellipse>
                    <ellipse id="Oval-7-Copy-18" fill="#1274BF" cx="138.728252" cy="59.4327485" rx="31.4026701" ry="31.4152047"></ellipse>
                    <ellipse id="Oval-7-Copy-19" fill="#1274BF" cx="36.9677003" cy="186.684211" rx="36.9677003" ry="36.9824561"></ellipse>
                    <ellipse id="Oval-7-Copy-11" fill="#1274BF" cx="311.641688" cy="152.087719" rx="22.3217054" ry="22.3306153"></ellipse>
                </g>
            </g>
        </g>
    </g>
</svg>)



## III .Gelişmiş sinir ağı teknikleri

### Önceki bölümde, çoğu sinir ağı yönteminin arkasındaki temel fikirleri tartıştık: çok katmanlı ağlar, doğrusal olmayan aktivasyon fonksiyonları ve backpropagation algoritması gibi öğrenme kuralları.

Onlar neredeyse tüm modern sinir ağı uygulamalarının güçlendiriyor. Bununla birlikte, birçok alanda derin öğrenmede büyük ilerlemelere yol açan temanın bazı ilginç ve güçlü varyasyonları vardır.

### Konvolüsyonel sinir ağları (CNN'ler)

Derin öğrenmenin olağanüstü bir başarı sağladığı alanlardan biri görüntü işlemedir. Önceki bölümde ayrıntılı olarak incelediğimiz basit sınıflandırıcı oldukça sınırlıdır - fark ettiğiniz gibi tüm gülen yüzleri doğru bir şekilde sınıflandırmak bile mümkün değildi. Ağa daha fazla katman eklemek ve ağırlıkları öğrenmek için geri yayılım kullanmak prensipte sorunu çözüyor, ancak bir başkası ortaya çıkıyor: ağırlıkların sayısı son derece büyük hale geliyor ve sonuç olarak tatmin edici bir doğruluk elde etmek için gereken egzersiz verilerinin miktarı çok büyük olmakta gerçekte.

Neyse ki, çok fazla ağırlık sorununa çok şık bir çözüm var: özel bir tür sinir ağı veya daha doğrusu, derin bir sinir ağına dahil edilebilecek özel bir katman türü. Bu özel tür katman, **evrişimli bir katmandır** . Evrişimli katmanları içeren **ağlara evrişimsel sinir ağları**(CNNs). Temel özellikleri parlak veya koyu (veya belirli renk) noktalar, çeşitli yönlerdeki kenarlar, desenler vb. Gibi görüntü özelliklerini algılayabilmeleridir. Bunlar, bir kedinin kulakları, bir köpeğin burnu, bir kişinin gözü veya bir durma işaretinin sekizgen şekli gibi daha soyut özellikleri tespit etmek için temel oluşturur. Girdi görüntünün piksellerine dayanarak bu özellikleri tespit etmek için normalde bir sinir ağını eğitmek zor olurdu, çünkü özellikler farklı konumlarda, farklı yönlerde ve görüntüdeki farklı boyutlarda görünebilir: nesneyi veya kamera açısını hareket ettirmek nesnenin kendisi aynı gözükse bile piksel değerlerini çarpıcı şekilde değiştirir. Tüm bu farklı koşullarda bir dur işareti tespit etmeyi öğrenmek için, çok miktarda eğitim verisi gerekir, çünkü ağ, sadece eğitim verilerinde göründüğü durumlarda oturum açmayı algılar. Bu nedenle, örneğin, görüntünün sağ üst köşesindeki bir dur işareti yalnızca eğitim verileri sağ üst köşede dur işareti olan bir görüntü içeriyorsa algılanır. CNN'ler, eğitim görüntülerinde nerede gözlemlendiğine bakmaksızın görüntüdeki herhangi bir nesneyi tanıyabilir.

> Not
>
> ## Neden CNN’lere ihtiyacımız var?
>
> CNN'ler, farklı koşullarda nesneleri algılamak için gereken egzersiz verisinin miktarını azaltmak için akıllıca bir numara kullanır. Püf noktası temel olarak birçok nöron için aynı girdi ağırlıklarını kullanmaktır - böylece tüm bu nöronlar aynı düzende aktive olur - ancak farklı giriş pikselleriyle. Örneğin, bir kedinin sivri kulağıyla harekete geçen bir dizi nöron olabilir. Girdi bir kedinin fotoğrafı olduğunda, biri sol kulak için diğeri sağ için olmak üzere iki nöron aktive edilir. Ayrıca nöronun giriş piksellerinin daha küçük veya daha büyük bir alandan alınmasına izin verebiliriz, böylece farklı nöronlar farklı ölçeklerde (boyutlarda) ortaya çıkan kulak tarafından aktive edilir, böylece sadece eğitim verisi olsa bile küçük bir kedinin kulaklarını tespit edebiliriz Büyük kedilerin görüntüleri dahil.

Evrişimli nöronlar tipik olarak ham girdi piksellerini işleyen ağın alt katmanlarına yerleştirilir. Bazik nöronlar (yukarıda tartışılan perceptron nöronu gibi) alt katmanların çıkışını işleyen daha yüksek katmanlara yerleştirilir. Alt katmanlar, genellikle göz önünde bulundurularak belirli bir tahmin görevi olmadan, denetimsiz öğrenme kullanılarak eğitilebilir. Giriş verilerinde sıkça görülen özellikleri algılamak için ağırlıkları ayarlanacaktır. Bu nedenle, hayvanların fotoğraflarıyla tipik özellikler kulaklar ve burunlar olacaktır; oysa bina görüntülerinde, özellikler duvarlar, çatılar, pencereler vb. Gibi mimari bileşenlerdir. Giriş verileri olarak çeşitli nesnelerin ve sahnelerin bir karışımı kullanılırsa, alt katmanlar tarafından öğrenilen özellikler aşağı yukarı genel olacaktır. Bu, önceden eğitilmiş evrişimli katmanların birçok farklı görüntü işleme görevinde tekrar kullanılabileceği anlamına gelir. Bu, son derece önemlidir çünkü neredeyse sınırsız miktarda etiketsiz eğitim verisi elde etmek kolaydır - etiketsiz görüntüler - alt katmanları eğitmek için kullanılabilir. Üst katmanlar her zaman geri yayılım gibi denetimli makine öğrenme teknikleri ile eğitilir.

![gan](assets/5_3-gan.dbb4be55.svg)



### Sinir ağları elektrikli koyunları hayal ediyor mu? GAN: Generative adversarial networks (GAN:Çekişmeli Üretici Ağlar)

Verilerden bir sinir ağı öğrenmiş, tahmin için kullanılabilir. Ağın üst katmanları belirli bir sınıflandırma veya tahmin görevi gerçekleştirmek için denetimli bir şekilde eğitildiğinden, üst katmanlar yalnızca bu görev için gerçekten kullanışlıdır. Dur işaretlerini tespit etmek için eğitilmiş bir ağ, el yazısı rakamları veya kedileri tespit etmek için kullanışsızdır.

Önceden eğitilmiş alt katmanları alarak ve öğrendikleri özelliklerin nasıl göründüğünü inceleyerek büyüleyici bir sonuç elde edilir. Bu, alt katmanlardaki belirli bir nöron setini aktive eden görüntüler üretilerek elde edilebilir. Oluşturulan görüntülere baktığımızda, sinir ağının belirli bir özelliğin "nasıl olduğunu" düşündüğünü veya içinde belirli özelliklere sahip bir görüntünün nasıl görüneceğini görebiliriz. Hatta bazıları görüntüleri “hayal kurmak” veya “halüsinasyon” gibi ağlar hakkında konuşmayı da [seviyor](https://en.wikipedia.org/wiki/DeepDream) (bkz. Google'ın [DeepDream sistemi](https://en.wikipedia.org/wiki/DeepDream) ).

> Not
>
> ## Metaforlara dikkat edin
>
> Bununla birlikte, giriş görüntüsünün basit optimizasyonunun ne zaman yapılması gerektiğini hayal etmek gibi bir metaforla ilgili sorunu bir kez daha vurgulamak istiyoruz - Bölüm 1'de tartışılan bavul sözcüklerini hatırlayın. Sinir ağı gerçekten hayal etmiyor ve İnsanın anladığı gibi benzer bir şekilde anlayabileceği bir kedi kavramına sahip değil. Nesneleri tanımak için eğitilmiştir ve üzerinde çalıştığı giriş verilerine benzer görüntüler üretebilir.

Gerçekte gerçek görünümlü kediler, insan yüzleri veya diğer nesneleri (eğitim verileri olarak ne kullanırsanız , onu alırsınız) üretmek için, şu anda Google [Beyin’de](https://en.wikipedia.org/wiki/Ian_Goodfellow) çalışan [Ian Goodfellow](https://en.wikipedia.org/wiki/Ian_Goodfellow) iki sinir ağının akıllıca bir kombinasyonunu önerdi. Fikir iki ağın birbiriyle rekabet etmesine izin vermektir. Ağlardan biri, eğitim verilerindeki gibi görüntüler üretmek için eğitilmiştir. Diğer ağın görevi, ilk ağ tarafından oluşturulan görüntüleri eğitim verilerinden ve  gerçek görüntülerden ayırmaktır - buna rakip ağ denir ve tüm sisteme üretici rakip ağ veya GAN denir.

Sistem iki modeli yan yana eğitiyor. Eğitimin başında, rakip modelin gerçek verileri eğitim verilerinden ve üretken modelin sakar girişimlerinden ayırmak için kolay bir görevi vardır. Bununla birlikte, üretici ağ yavaş yavaş daha iyi ve daha iyi hale geldikçe, rakip modelin de gelişmesi gerekir ve sonuçta üretilen görüntüler neredeyse gerçeklerden ayırt edilemez olana kadar devam eder. GAN, sadece eğitim verilerindeki görüntüleri çoğaltmaya çalışmaz: yanında rakip ağı yenmek için çok basit bir strateji olabilir. Ancak, sistem, yeni ve gerçek görünümlü görüntüler üretebilmek için de eğitilmiştir.

![fakecelebrityfaces](assets/5_3_fake-celebrity-ac3753c9c9a3248de4bc71231b483be1-c341a.jpg)

Yukarıdaki görüntüler NVIDIA tarafından [Prof Jaakko Lehtinen](https://users.aalto.fi/~lehtinj7/) tarafından yürütülen bir projede geliştirilen bir GAN tarafından üretildi ( [daha fazla ayrıntı için bu makaleye bakın](https://www.technologyreview.com/the-download/609290/meet-the-fake-celebrities-dreamed-up-by-ai/) ).

Onları sahte olarak tanıyabilir miydin?

### Bölüm 5'i tamamladıktan sonra:

- Bir sinir ağının ne olduğunu ve nerede başarıyla kullanıldığını açıklayın.
- Yapay sinir ağlarını destekleyen teknik yöntemleri anlayın